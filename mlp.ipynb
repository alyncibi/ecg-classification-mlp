{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFramesFromCSV(filename):\n",
    "    fullV5 = pd.read_csv(filename, usecols=[2]) # extraction of V5 column\n",
    "    fullV5 = (fullV5 - 1024 )/ 200 # normalization\n",
    "    frameLength = 2/(1/360) # 2 seconds => 2 * (1/360) samples per segment ..\n",
    "    framesCount = int(fullV5.shape[0] / frameLength) # how many frames I can Extract ?\n",
    "    usedV5 = fullV5[0:int(framesCount * frameLength)] # only useful last will be ignored\n",
    "    frames = []\n",
    "    for i in range(1,framesCount+1):\n",
    "        frames.append(usedV5[int((i-1)*frameLength):int(i*frameLength)])\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from csv files into lists of dataframes\n",
    "ListNormalFrames1 = readFramesFromCSV(\"100normal-pre-training.csv\")\n",
    "ListNormalFrames2 = readFramesFromCSV(\"101normal-pre-testing.csv\")\n",
    "ListRbbbFrames1 = readFramesFromCSV(\"118rbbb-pre-training.csv\")\n",
    "ListRbbbFrames2 = readFramesFromCSV(\"231rbbb-pre-testing.csv\")\n",
    "\n",
    "# conversion to matrix\n",
    "Normal1 = np.array([np.array(xi) for xi in ListNormalFrames1])\n",
    "Normal2 = np.array([np.array(xi) for xi in ListNormalFrames2])\n",
    "Rbbb1 = np.array([np.array(xi) for xi in ListRbbbFrames1])\n",
    "Rbbb2 = np.array([np.array(xi) for xi in ListRbbbFrames2])\n",
    "\n",
    "# aggregation\n",
    "Normalinput = np.concatenate((Normal1,Normal2))\n",
    "Rbbbinput = np.concatenate((Rbbb1,Rbbb2))\n",
    "Input = np.concatenate((Normalinput,Rbbbinput))\n",
    "Normaloutput = np.ones((len(Normalinput),1))\n",
    "Rbbboutput = np.zeros((len(Rbbbinput),1))\n",
    "for i in range(len(Rbbboutput)):\n",
    "    Rbbboutput[i] += -1\n",
    "Output = np.concatenate((Normaloutput,Rbbboutput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set/ test set splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Input, Output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = X_train.reshape((len(X_train),len(X_train[0])))\n",
    "X_test = X_test.reshape((len(X_test),len(X_test[0])))\n",
    "Y_train = Y_train.reshape(-1)\n",
    "Y_test  = Y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy = 0.7063711911357341\n"
     ]
    }
   ],
   "source": [
    "# Perceptron training & prediction\n",
    "ptn = Perceptron(max_iter=500,tol=1e-3 )\n",
    "ptn.fit(X_train, Y_train)  \n",
    "Y_pred = ptn.predict(X_test)\n",
    "accuracy = metric.accuracy_score(Y_test.T, Y_pred, normalize=True)\n",
    "print('acuracy =',accuracy)                         # show accracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy= 0.9542936288088643\n"
     ]
    }
   ],
   "source": [
    "# MLP training & prediction\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(8,8), activation='relu') # set the method\n",
    "mlp.fit(X_train, Y_train)                    # training\n",
    "Y_pred = mlp.predict(X_test)                      # prediction\n",
    "accuracy = metric.accuracy_score(np.array(Y_test).flatten(), np.array(Y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)        # show accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
